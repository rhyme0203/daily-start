import { BaseCrawler } from '../baseCrawler'
import { CrawledPost, CrawlerConfig } from '../types'

export class EmpakCrawler extends BaseCrawler {
  constructor() {
    const config: CrawlerConfig = {
      siteName: 'ì— íŒ',
      siteCode: 'empak',
      baseUrl: 'https://mlbpark.donga.com',
      listUrl: 'https://mlbpark.donga.com/mp/b.php?b=bullpen',
      contentSelectors: [
        'div.ar_txt#contentDetail',
        '.ar_txt#contentDetail',
        'div.ar_txt',
        '#contentDetail',
        '.ar_txt'
      ],
      unwantedElements: [
        'script', 'style', 'nav', 'header', 'footer', '.ad', '.advertisement', 
        '.banner', '.sidebar', '.comment', '.reply', '.related', '.recommend',
        '.menu', '.navigation', '.aside', '.widget', '.popup', '.ads',
        '.ad-banner', '.sponsor', 'label', 'input', 'button', 'form',
        '.login', '.signup', '.auth', '.user', '.member', '.profile',
        '.account', '.settings', '.config', '.option', '.checkbox', '.radio',
        '.select', '.keepid', '.login-optn', '.signup-optn', '.favorite-text',
        '.favorite', '.bookmark', '.like', '.share', '.social', '.toolbar',
        '.action', '.btn', '.button', '.comment-list', '.comment-item',
        '.reply-list', '.reply-item', '.comment-area', '.reply-area',
        '.comment-box', '.reply-box', '.comment-section', '.reply-section',
        '.comment-container', '.reply-container', '.thumb', 'img', '.image',
        '.photo', '.picture', '.media', '.gallery', '.carousel', '.slider', '.tool_cont'
      ],
      unwantedTexts: [
        'ìŠ¤í¬ë© AD', 'í•œí™”ìƒëª…', 'eì •ê¸°ë³´í—˜', 'ë³´í—˜ë£Œ', 'ì‚¬ë§ë³´í—˜',
        'ì´ë²¤íŠ¸', 'ë„¤ì´ë²„í˜ì´', 'í•œí™”ì†í•´ë³´í—˜', 'ìºë¡¯', 'ìë™ì°¨ë³´í—˜',
        'ìš´ì „ìë³´í—˜', 'ê²Œì„', 'ë°°í‹€ë„·', 'ì„±ì ', 'ìŠ¹ë¥ ', 'í™ì§„í˜¸',
        'ë°•ì •ì„', 'ë³„ëª…', 'ê¹€ì„œí˜„', 'ë‚˜ì˜¤ë‚˜ìš”', 'ë¯€',
        'ë°•ìš©ìš°', 'ì‚¬ë§ ë³´í—˜ê¸ˆ', 'ë¶€ë‹¹ ì·¨ë“', 'ì˜í˜¹', 'ì†í•´ì‚¬ì •ì‚¬',
        'ë„Œì„¼ìŠ¤', 'dimg.donga.com', 'IMAGE', 'SPORTS', 'wps',
        'thumb', 'alt=', 'src=', 'jpg', 'png', 'gif', 'webp',
        'tool_cont', '== $0', 'ğŸ‘€', 'ì¡°íšŒìˆ˜', 'ì¡°íšŒ', 'ê³µê°', 'ì¶”ì²œ', 'ë¹„ì¶”ì²œ',
        'ì‹¤ì‹œê°„ë¬´ë£Œëˆ„ìˆ˜ìƒë‹´', 'ë°±ê°•ëˆ„ìˆ˜', 'ë°±ê°•ëˆ„ìˆ˜íƒì§€ê¸°ìˆ í•™ì›', 'ëˆ„ìˆ˜íƒì§€', 'ë¬´ë£Œìƒë‹´',
        'ì´ë²¤íŠ¸ë²•ì ', 'í•˜ìë³´ìˆ˜ê¸°ê°„', 'ì¸ì •ì—…ì²´', 'ì—°ì„¸ê³ ìš´ë¯¸ì†Œì¹˜ê³¼ì˜ì›', 'ë¶„ë‹¹ì ',
        'ë¯¸ê¸ˆì—­7ë²ˆì¶œêµ¬', 'ì›”í™”ìˆ˜ëª©ì•¼ê°„ì§„ë£Œ', 'êµì •', 'ì„í”Œë€íŠ¸', 'ì‚¬ë‘ë‹ˆ', 'ì˜ˆë°©',
        'ì¼ìƒ', 'ì¼ë³¸ ì†Œë„ì‹œ', 'ì™¸êµ­ì¸', 'ë„ì™€ì£¼ë ¤ëŠ”', 'ì¼ë³¸ë…€', 'ì•ˆì†Œí˜„',
        'ê²°í˜¼ì ë ¹ê¸°', 'í•œêµ­ì—¬ì', 'ê°‘ì¸ê±°', 'ë¶ˆí¸í•œíŒ©íŠ¸', 'ìš°ì •ì‰', 'ì£¼ì‹ê³„ì¢Œ',
        'ê·¼í™©', 'ê³µê°œ', 'ë ˆë“œì œí”Œë¦°', 'ê³ ë¯¼ìƒë‹´', 'ê²½í¬ëŒ€', 'ì™¸ëŒ€', 'ì‹œë¦½ëŒ€',
        'êµë¥˜', 'ì¹œí•œê°€ìš”', 'ì›”ë¥˜ë´‰', 'ì„¤ìœ¤', 'í•œê³„ê°€ ìˆëŠ”', 'ì–¼êµ´ì´ì£ ',
        'ìš©ì™•', 'ì¶•êµ¬', 'ì§¤ë°©í‰ì ', 'í•©ë¦¬ì ì¸ ì´ìœ ', 'ê°€ ê°€ ìŠ¤í¬ë©',
        '09:54:', '14775104', '14775103', '14775102', '14775101', '14775100',
        'JPG', 'jpg', 'PNG', 'png', 'GIF', 'gif', 'WEBP', 'webp',
        'ì´ë¯¸ì§€', 'ì‚¬ì§„', 'ê·¸ë¦¼', 'ì²¨ë¶€íŒŒì¼', 'ì²¨ë¶€', 'íŒŒì¼'
      ],
      updateInterval: 60 // 1ì‹œê°„
    }
    super(config)
  }

  async crawlPosts(): Promise<CrawledPost[]> {
    try {
      const html = await this.fetchWithProxy(this.config.listUrl)
      const doc = this.parseHtml(html)
      
      const posts: CrawledPost[] = []
      
      // ì— íŒ ê²Œì‹œê¸€ ëª©ë¡ íŒŒì‹±
      const postElements = doc.querySelectorAll('.list_row, .list_item, .board_list tr, .list_table tr')
      
      postElements.forEach((element, index) => {
        if (index >= 10) return // ìµœëŒ€ 10ê°œë§Œ
        
        try {
          const titleElement = element.querySelector('a[href*="/mp/b.php"]')
          const title = titleElement?.textContent?.trim() || ''
          const url = titleElement?.getAttribute('href') || ''
          const viewsElement = element.querySelector('.hit, .view_count, .list_count')
          const views = viewsElement?.textContent?.trim() || '0'
          const timeElement = element.querySelector('.time, .date, .list_time')
          const time = timeElement?.textContent?.trim() || new Date().toLocaleTimeString('ko-KR', { hour: '2-digit', minute: '2-digit' })
          
          if (title && url) {
            const fullUrl = url.startsWith('http') ? url : this.config.baseUrl + url
            const postId = this.generatePostId(this.config.siteCode, title, time)
            
            posts.push({
              id: postId,
              site: this.config.siteName,
              siteCode: this.config.siteCode,
              title,
              url: fullUrl,
              views,
              time,
              timestamp: Date.now()
            })
          }
        } catch (error) {
          console.warn('Error parsing post element:', error)
        }
      })
      
      return posts
    } catch (error) {
      console.error('Error crawling Empak posts:', error)
      return []
    }
  }

  async crawlPostContent(postUrl: string): Promise<string> {
    try {
      const html = await this.fetchWithProxy(postUrl)
      const doc = this.parseHtml(html)
      
      let contentElement: Element | null = null
      
      // ì— íŒì€ div.ar_txt ì˜ì—­ë§Œ ì„ íƒ (tool_cont ë“±ì€ ì™„ì „íˆ ì œì™¸)
      const arTxtElement = doc.querySelector('div.ar_txt#contentDetail') || 
                          doc.querySelector('.ar_txt#contentDetail') || 
                          doc.querySelector('div.ar_txt') || 
                          doc.querySelector('#contentDetail') || 
                          doc.querySelector('.ar_txt')
      
      if (arTxtElement) {
        contentElement = arTxtElement
      }
      
      if (!contentElement) {
        return 'ë³¸ë¬¸ ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
      }
      
      return this.cleanContent(contentElement)
    } catch (error) {
      console.error('Error crawling Empak post content:', error)
      return 'ë³¸ë¬¸ ë‚´ìš©ì„ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.'
    }
  }
}
